{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-13T16:24:31.715207Z",
     "start_time": "2025-01-13T16:24:31.532305Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from litedl.utils import OneHotEncoder, MinMaxScaler, data_split, get_batches, Standardizer\n",
    "from litedl.models import FeedForwardNeuralNetwork\n",
    "from litedl.layers import Affine, Sigmoid, SoftmaxWithLoss, ReLU\n",
    "from litedl.optimizers import SGD\n",
    "\n",
    "epoch = 100\n",
    "batch_size = 100\n",
    "\n",
    "dataset = pd.read_csv('dataset/heart_attack_risk_dataset.csv')\n",
    "feature_dataset = dataset.iloc[:, :-1]\n",
    "label_dataset = dataset.iloc[:, -1]\n",
    "\n",
    "categorical = ['Gender', 'Physical_Activity_Level', 'Stress_Level', 'Chest_Pain_Type', 'Thalassemia', 'ECG_Results']\n",
    "binary = ['Smoking', 'Alcohol_Consumption', 'Diabetes', 'Hypertension', 'Family_History', 'Fasting_Blood_Sugar', 'Exercise_Induced_Angina']\n",
    "num = ['Age', 'BMI', 'Cholesterol_Level', 'Resting_BP', 'Heart_Rate', 'Max_Heart_Rate_Achieved']\n",
    "\n",
    "categorical_dataset = pd.get_dummies(feature_dataset[categorical]).astype(np.int32)\n",
    "categorical_data = categorical_dataset.values\n",
    "\n",
    "binary_data = feature_dataset[binary].values\n",
    "binary_dataset = pd.DataFrame(binary_data, columns=binary)\n",
    "\n",
    "num_data = feature_dataset[num].values\n",
    "num_scaler = MinMaxScaler()\n",
    "num_scaler.fit(num_data)\n",
    "num_data = num_scaler.transform(num_data)\n",
    "num_dataset = pd.DataFrame(num_data, columns=num)\n",
    "\n",
    "label_data = label_dataset.values.reshape(-1, 1)\n",
    "label_encoder = OneHotEncoder()\n",
    "label_encoder.fit(label_data)\n",
    "labels = label_encoder.transform(label_data)\n",
    "\n",
    "feature_dataset = pd.concat([categorical_dataset, binary_dataset, num_dataset], axis=1)\n",
    "features = feature_dataset.values\n",
    "\n",
    "train_features, test_features = data_split(features, 0.2)\n",
    "train_labels, test_labels = data_split(labels, 0.2)\n",
    "\n",
    "feature_batches = get_batches(train_features, batch_size)\n",
    "label_batches = get_batches(train_labels, batch_size)"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:24:33.988350Z",
     "start_time": "2025-01-13T16:24:31.715207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = FeedForwardNeuralNetwork()\n",
    "affine1 = Affine(input_size=31, output_size=3)\n",
    "relu1 = ReLU()\n",
    "affine2 = Affine(input_size=100, output_size=50)\n",
    "relu2 = ReLU()\n",
    "affine3 = Affine(input_size=50, output_size=3)\n",
    "softmax_loss = SoftmaxWithLoss()\n",
    "sgd = SGD()\n",
    "\n",
    "model.add_layer(affine1)\n",
    "'''model.add_layer(relu1)\n",
    "model.add_layer(affine2)\n",
    "model.add_layer(relu2)\n",
    "model.add_layer(affine3)'''\n",
    "model.add_loss_layer(softmax_loss)\n",
    "\n",
    "for i in range(epoch):\n",
    "    losses = []\n",
    "    for j in range(len(feature_batches)):\n",
    "        losses.append(model.forward(feature_batches[j], label_batches[j]))\n",
    "        model.backward()\n",
    "        model.step(optimizer=sgd)\n",
    "        \n",
    "    print(f'epoch {i}: {sum(losses) / len(losses)}')"
   ],
   "id": "f9349db126d7e4da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: -9.99999950583871e-08\n",
      "epoch 1: -9.99999950583871e-08\n",
      "epoch 2: -9.99999950583871e-08\n",
      "epoch 3: -9.99999950583871e-08\n",
      "epoch 4: -9.99999950583871e-08\n",
      "epoch 5: -9.99999950583871e-08\n",
      "epoch 6: -9.99999950583871e-08\n",
      "epoch 7: -9.99999950583871e-08\n",
      "epoch 8: -9.99999950583871e-08\n",
      "epoch 9: -9.99999950583871e-08\n",
      "epoch 10: -9.99999950583871e-08\n",
      "epoch 11: -9.99999950583871e-08\n",
      "epoch 12: -9.99999950583871e-08\n",
      "epoch 13: -9.99999950583871e-08\n",
      "epoch 14: -9.99999950583871e-08\n",
      "epoch 15: -9.99999950583871e-08\n",
      "epoch 16: -9.99999950583871e-08\n",
      "epoch 17: -9.99999950583871e-08\n",
      "epoch 18: -9.99999950583871e-08\n",
      "epoch 19: -9.99999950583871e-08\n",
      "epoch 20: -9.99999950583871e-08\n",
      "epoch 21: -9.99999950583871e-08\n",
      "epoch 22: -9.99999950583871e-08\n",
      "epoch 23: -9.99999950583871e-08\n",
      "epoch 24: -9.99999950583871e-08\n",
      "epoch 25: -9.99999950583871e-08\n",
      "epoch 26: -9.99999950583871e-08\n",
      "epoch 27: -9.99999950583871e-08\n",
      "epoch 28: -9.99999950583871e-08\n",
      "epoch 29: -9.99999950583871e-08\n",
      "epoch 30: -9.99999950583871e-08\n",
      "epoch 31: -9.99999950583871e-08\n",
      "epoch 32: -9.99999950583871e-08\n",
      "epoch 33: -9.99999950583871e-08\n",
      "epoch 34: -9.99999950583871e-08\n",
      "epoch 35: -9.99999950583871e-08\n",
      "epoch 36: -9.99999950583871e-08\n",
      "epoch 37: -9.99999950583871e-08\n",
      "epoch 38: -9.99999950583871e-08\n",
      "epoch 39: -9.99999950583871e-08\n",
      "epoch 40: -9.99999950583871e-08\n",
      "epoch 41: -9.99999950583871e-08\n",
      "epoch 42: -9.99999950583871e-08\n",
      "epoch 43: -9.99999950583871e-08\n",
      "epoch 44: -9.99999950583871e-08\n",
      "epoch 45: -9.99999950583871e-08\n",
      "epoch 46: -9.99999950583871e-08\n",
      "epoch 47: -9.99999950583871e-08\n",
      "epoch 48: -9.99999950583871e-08\n",
      "epoch 49: -9.99999950583871e-08\n",
      "epoch 50: -9.99999950583871e-08\n",
      "epoch 51: -9.99999950583871e-08\n",
      "epoch 52: -9.99999950583871e-08\n",
      "epoch 53: -9.99999950583871e-08\n",
      "epoch 54: -9.99999950583871e-08\n",
      "epoch 55: -9.99999950583871e-08\n",
      "epoch 56: -9.99999950583871e-08\n",
      "epoch 57: -9.99999950583871e-08\n",
      "epoch 58: -9.99999950583871e-08\n",
      "epoch 59: -9.99999950583871e-08\n",
      "epoch 60: -9.99999950583871e-08\n",
      "epoch 61: -9.99999950583871e-08\n",
      "epoch 62: -9.99999950583871e-08\n",
      "epoch 63: -9.99999950583871e-08\n",
      "epoch 64: -9.99999950583871e-08\n",
      "epoch 65: -9.99999950583871e-08\n",
      "epoch 66: -9.99999950583871e-08\n",
      "epoch 67: -9.99999950583871e-08\n",
      "epoch 68: -9.99999950583871e-08\n",
      "epoch 69: -9.99999950583871e-08\n",
      "epoch 70: -9.99999950583871e-08\n",
      "epoch 71: -9.99999950583871e-08\n",
      "epoch 72: -9.99999950583871e-08\n",
      "epoch 73: -9.99999950583871e-08\n",
      "epoch 74: -9.99999950583871e-08\n",
      "epoch 75: -9.99999950583871e-08\n",
      "epoch 76: -9.99999950583871e-08\n",
      "epoch 77: -9.99999950583871e-08\n",
      "epoch 78: -9.99999950583871e-08\n",
      "epoch 79: -9.99999950583871e-08\n",
      "epoch 80: -9.99999950583871e-08\n",
      "epoch 81: -9.99999950583871e-08\n",
      "epoch 82: -9.99999950583871e-08\n",
      "epoch 83: -9.99999950583871e-08\n",
      "epoch 84: -9.99999950583871e-08\n",
      "epoch 85: -9.99999950583871e-08\n",
      "epoch 86: -9.99999950583871e-08\n",
      "epoch 87: -9.99999950583871e-08\n",
      "epoch 88: -9.99999950583871e-08\n",
      "epoch 89: -9.99999950583871e-08\n",
      "epoch 90: -9.99999950583871e-08\n",
      "epoch 91: -9.99999950583871e-08\n",
      "epoch 92: -9.99999950583871e-08\n",
      "epoch 93: -9.99999950583871e-08\n",
      "epoch 94: -9.99999950583871e-08\n",
      "epoch 95: -9.99999950583871e-08\n",
      "epoch 96: -9.99999950583871e-08\n",
      "epoch 97: -9.99999950583871e-08\n",
      "epoch 98: -9.99999950583871e-08\n",
      "epoch 99: -9.99999950583871e-08\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:24:33.997228Z",
     "start_time": "2025-01-13T16:24:33.988350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_prediction = model.predict(test_features)\n",
    "test_prediction = np.argmax(test_prediction, axis=1)\n",
    "test_answer = np.argmax(test_labels, axis=1)\n",
    "\n",
    "same_count = np.sum(test_prediction == test_answer)\n",
    "accuracy = same_count / test_prediction.shape[0]\n",
    "\n",
    "print(f'정확도: {accuracy}')"
   ],
   "id": "146aa653f878cc29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.5024\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:24:34.001446Z",
     "start_time": "2025-01-13T16:24:33.998776Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1c77b0a89fdbcd37",
   "outputs": [],
   "execution_count": 66
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
